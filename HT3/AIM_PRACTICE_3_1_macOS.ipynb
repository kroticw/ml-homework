{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Черновой вариант, но с torch",
   "id": "23ee56868d1ee9b4"
  },
  {
   "cell_type": "code",
   "id": "7346417cf765099d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:20.971251Z",
     "start_time": "2024-12-03T13:34:20.942804Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from random import shuffle\n",
    "import cv2"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "id": "1a93391c58880a95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:20.998369Z",
     "start_time": "2024-12-03T13:34:20.984554Z"
    }
   },
   "source": [
    "class NumericDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, img_size, num_classes, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_size = img_size # !!! внимательно при изменении размеров изображения\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "        file_names = []\n",
    "        class_labels = []\n",
    "        print(os.walk(path_to_folder))\n",
    "        for path, subdirs, files in os.walk(path_to_folder):\n",
    "            if path != self.root_dir:\n",
    "                for (idx,name) in enumerate(files):\n",
    "                    if(idx < MAX_FILES):\n",
    "                        file_names.append(os.path.join(path, name))\n",
    "                        class_labels.append(dict_folders[path.split('/')[-1]])\n",
    "        self.files = [[file_names[i],class_labels[i]] for i in range(len(file_names))]#!!!\n",
    "        shuffle(self.files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx][0]\n",
    "\n",
    "        img = cv2.imread(img_name, cv2.COLOR_RGB2GRAY)\n",
    "        image = img\n",
    "        image = cv2.resize(image,(self.img_size, self.img_size))\n",
    "        image = cv2.bitwise_not(image) / 255\n",
    "        image = np.asarray(image).astype(float)#.reshape(3,self.img_size,self.img_size)\n",
    "\n",
    "        target = [0 for i in range(self.num_classes)]\n",
    "        target[self.files[idx][1]] = 1\n",
    "        target = torch.FloatTensor(target)\n",
    "\n",
    "        image = torch.FloatTensor(image[:,:,0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image,target,self.files[idx][1]\n"
   ],
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "id": "7a2e3b1637e59265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:21.044183Z",
     "start_time": "2024-12-03T13:34:21.039935Z"
    }
   },
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(IMAGE_SIZE*IMAGE_SIZE, 4*IMAGE_SIZE*IMAGE_SIZE)\n",
    "        #self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(4*IMAGE_SIZE*IMAGE_SIZE, 4*NUM_CLASSES)\n",
    "        #self.fc2_drop = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(4*NUM_CLASSES, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, IMAGE_SIZE*IMAGE_SIZE)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.fc3(x)\n"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "id": "4ffa014d97d8e879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:21.059119Z",
     "start_time": "2024-12-03T13:34:21.054936Z"
    }
   },
   "source": [
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    k = 0\n",
    "    for batch_idx, (data, target,idx_class) in enumerate(num_train_dataloader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        #print(output,target)\n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss += loss.item()\n",
    "        k+=1\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Epoch_Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(num_train_dataloader.dataset),\n",
    "                100. * batch_idx / len(num_train_dataloader), loss.data.item(), epoch_loss))\n",
    "    return epoch_loss / k"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "id": "a011dbaa8781a6f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:21.075994Z",
     "start_time": "2024-12-03T13:34:21.073348Z"
    }
   },
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:21.407027Z",
     "start_time": "2024-12-03T13:34:21.089751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_folder = './data' # путь к папке с данными\n",
    "name_folders = [x[0].split('/')[-1] for x in os.walk(path_to_folder)]\n",
    "name_folders = name_folders[1:]\n",
    "print(name_folders)"
   ],
   "id": "e11091fb731b450c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['times', '9', '0', '7', '+', ',', '6', '1', '8', '1', 't', '-', 'h', '(', '4', 'X', '3', ')', '2', 'y', '5', 'w']\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:21.781878Z",
     "start_time": "2024-12-03T13:34:21.425699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_CLASSES = len(name_folders)\n",
    "MAX_FILES = 3\n",
    "\n",
    "class_idx = [i for i in range(len(name_folders))]\n",
    "dict_folders = {name_folders[i]:class_idx[i] for i in range(len(class_idx))}\n",
    "\n",
    "file_names = []\n",
    "class_labels = []\n",
    "for path, subdirs, files in os.walk(path_to_folder):\n",
    "    folder_name = path.rstrip('/').split('/')[-1]  # Убираем лишний '/' и получаем имя папки\n",
    "    if folder_name in dict_folders:\n",
    "        for name in files:\n",
    "            file_names.append(os.path.join(path, name))\n",
    "            class_labels.append(dict_folders[folder_name])\n"
   ],
   "id": "b930f129e0b2d54e",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:32.692431Z",
     "start_time": "2024-12-03T13:34:21.796389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 10\n",
    "IMAGE_SIZE = 32\n",
    "num_train_dataloader = DataLoader(NumericDataset(path_to_folder,IMAGE_SIZE,NUM_CLASSES), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for (X_train, y_train,class_idx) in num_train_dataloader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break\n",
    "\n",
    "epoch_start = 0\n",
    "epochs = 1000\n",
    "path_model_save = './models/'\n",
    "\n",
    "model = Net().to(device) #!!!\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "lossv = []\n",
    "for epoch in range(epoch_start, epochs + 1):\n",
    "    lossv.append(train(epoch))\n"
   ],
   "id": "7d073076537081bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _walk at 0x321835660>\n",
      "X_train: torch.Size([10, 32, 32]) type: torch.FloatTensor\n",
      "y_train: torch.Size([10, 22]) type: torch.FloatTensor\n",
      "Train Epoch: 0 [0/66 (0%)]\tLoss: 3.095054 Epoch_Loss: 3.095054\n",
      "Train Epoch: 1 [0/66 (0%)]\tLoss: 3.093458 Epoch_Loss: 3.093458\n",
      "Train Epoch: 2 [0/66 (0%)]\tLoss: 3.088918 Epoch_Loss: 3.088918\n",
      "Train Epoch: 3 [0/66 (0%)]\tLoss: 3.038775 Epoch_Loss: 3.038775\n",
      "Train Epoch: 4 [0/66 (0%)]\tLoss: 3.044761 Epoch_Loss: 3.044761\n",
      "Train Epoch: 5 [0/66 (0%)]\tLoss: 3.047883 Epoch_Loss: 3.047883\n",
      "Train Epoch: 6 [0/66 (0%)]\tLoss: 3.015374 Epoch_Loss: 3.015374\n",
      "Train Epoch: 7 [0/66 (0%)]\tLoss: 2.978432 Epoch_Loss: 2.978432\n",
      "Train Epoch: 8 [0/66 (0%)]\tLoss: 2.987219 Epoch_Loss: 2.987219\n",
      "Train Epoch: 9 [0/66 (0%)]\tLoss: 2.917384 Epoch_Loss: 2.917384\n",
      "Train Epoch: 10 [0/66 (0%)]\tLoss: 2.891125 Epoch_Loss: 2.891125\n",
      "Train Epoch: 11 [0/66 (0%)]\tLoss: 2.891299 Epoch_Loss: 2.891299\n",
      "Train Epoch: 12 [0/66 (0%)]\tLoss: 2.940033 Epoch_Loss: 2.940033\n",
      "Train Epoch: 13 [0/66 (0%)]\tLoss: 2.891443 Epoch_Loss: 2.891443\n",
      "Train Epoch: 14 [0/66 (0%)]\tLoss: 2.913161 Epoch_Loss: 2.913161\n",
      "Train Epoch: 15 [0/66 (0%)]\tLoss: 2.879167 Epoch_Loss: 2.879167\n",
      "Train Epoch: 16 [0/66 (0%)]\tLoss: 2.867794 Epoch_Loss: 2.867794\n",
      "Train Epoch: 17 [0/66 (0%)]\tLoss: 2.848279 Epoch_Loss: 2.848279\n",
      "Train Epoch: 18 [0/66 (0%)]\tLoss: 2.807458 Epoch_Loss: 2.807458\n",
      "Train Epoch: 19 [0/66 (0%)]\tLoss: 2.759391 Epoch_Loss: 2.759391\n",
      "Train Epoch: 20 [0/66 (0%)]\tLoss: 2.713405 Epoch_Loss: 2.713405\n",
      "Train Epoch: 21 [0/66 (0%)]\tLoss: 2.763978 Epoch_Loss: 2.763978\n",
      "Train Epoch: 22 [0/66 (0%)]\tLoss: 2.755852 Epoch_Loss: 2.755852\n",
      "Train Epoch: 23 [0/66 (0%)]\tLoss: 2.748154 Epoch_Loss: 2.748154\n",
      "Train Epoch: 24 [0/66 (0%)]\tLoss: 2.751637 Epoch_Loss: 2.751637\n",
      "Train Epoch: 25 [0/66 (0%)]\tLoss: 2.685590 Epoch_Loss: 2.685590\n",
      "Train Epoch: 26 [0/66 (0%)]\tLoss: 2.654970 Epoch_Loss: 2.654970\n",
      "Train Epoch: 27 [0/66 (0%)]\tLoss: 2.671401 Epoch_Loss: 2.671401\n",
      "Train Epoch: 28 [0/66 (0%)]\tLoss: 2.632746 Epoch_Loss: 2.632746\n",
      "Train Epoch: 29 [0/66 (0%)]\tLoss: 2.599895 Epoch_Loss: 2.599895\n",
      "Train Epoch: 30 [0/66 (0%)]\tLoss: 2.655362 Epoch_Loss: 2.655362\n",
      "Train Epoch: 31 [0/66 (0%)]\tLoss: 2.656071 Epoch_Loss: 2.656071\n",
      "Train Epoch: 32 [0/66 (0%)]\tLoss: 2.466710 Epoch_Loss: 2.466710\n",
      "Train Epoch: 33 [0/66 (0%)]\tLoss: 2.610356 Epoch_Loss: 2.610356\n",
      "Train Epoch: 34 [0/66 (0%)]\tLoss: 2.610058 Epoch_Loss: 2.610058\n",
      "Train Epoch: 35 [0/66 (0%)]\tLoss: 2.593733 Epoch_Loss: 2.593733\n",
      "Train Epoch: 36 [0/66 (0%)]\tLoss: 2.479665 Epoch_Loss: 2.479665\n",
      "Train Epoch: 37 [0/66 (0%)]\tLoss: 2.453583 Epoch_Loss: 2.453583\n",
      "Train Epoch: 38 [0/66 (0%)]\tLoss: 2.621409 Epoch_Loss: 2.621409\n",
      "Train Epoch: 39 [0/66 (0%)]\tLoss: 2.414907 Epoch_Loss: 2.414907\n",
      "Train Epoch: 40 [0/66 (0%)]\tLoss: 2.336759 Epoch_Loss: 2.336759\n",
      "Train Epoch: 41 [0/66 (0%)]\tLoss: 2.354883 Epoch_Loss: 2.354883\n",
      "Train Epoch: 42 [0/66 (0%)]\tLoss: 2.360007 Epoch_Loss: 2.360007\n",
      "Train Epoch: 43 [0/66 (0%)]\tLoss: 2.185665 Epoch_Loss: 2.185665\n",
      "Train Epoch: 44 [0/66 (0%)]\tLoss: 2.278208 Epoch_Loss: 2.278208\n",
      "Train Epoch: 45 [0/66 (0%)]\tLoss: 2.176240 Epoch_Loss: 2.176240\n",
      "Train Epoch: 46 [0/66 (0%)]\tLoss: 2.136781 Epoch_Loss: 2.136781\n",
      "Train Epoch: 47 [0/66 (0%)]\tLoss: 2.188470 Epoch_Loss: 2.188470\n",
      "Train Epoch: 48 [0/66 (0%)]\tLoss: 2.059391 Epoch_Loss: 2.059391\n",
      "Train Epoch: 49 [0/66 (0%)]\tLoss: 2.190033 Epoch_Loss: 2.190033\n",
      "Train Epoch: 50 [0/66 (0%)]\tLoss: 2.178094 Epoch_Loss: 2.178094\n",
      "Train Epoch: 51 [0/66 (0%)]\tLoss: 2.152677 Epoch_Loss: 2.152677\n",
      "Train Epoch: 52 [0/66 (0%)]\tLoss: 2.045382 Epoch_Loss: 2.045382\n",
      "Train Epoch: 53 [0/66 (0%)]\tLoss: 1.891795 Epoch_Loss: 1.891795\n",
      "Train Epoch: 54 [0/66 (0%)]\tLoss: 2.193923 Epoch_Loss: 2.193923\n",
      "Train Epoch: 55 [0/66 (0%)]\tLoss: 2.305930 Epoch_Loss: 2.305930\n",
      "Train Epoch: 56 [0/66 (0%)]\tLoss: 2.074833 Epoch_Loss: 2.074833\n",
      "Train Epoch: 57 [0/66 (0%)]\tLoss: 2.249485 Epoch_Loss: 2.249485\n",
      "Train Epoch: 58 [0/66 (0%)]\tLoss: 1.669942 Epoch_Loss: 1.669942\n",
      "Train Epoch: 59 [0/66 (0%)]\tLoss: 1.885298 Epoch_Loss: 1.885298\n",
      "Train Epoch: 60 [0/66 (0%)]\tLoss: 2.140873 Epoch_Loss: 2.140873\n",
      "Train Epoch: 61 [0/66 (0%)]\tLoss: 1.920371 Epoch_Loss: 1.920371\n",
      "Train Epoch: 62 [0/66 (0%)]\tLoss: 1.807562 Epoch_Loss: 1.807562\n",
      "Train Epoch: 63 [0/66 (0%)]\tLoss: 1.748994 Epoch_Loss: 1.748994\n",
      "Train Epoch: 64 [0/66 (0%)]\tLoss: 1.834820 Epoch_Loss: 1.834820\n",
      "Train Epoch: 65 [0/66 (0%)]\tLoss: 1.673012 Epoch_Loss: 1.673012\n",
      "Train Epoch: 66 [0/66 (0%)]\tLoss: 1.596843 Epoch_Loss: 1.596843\n",
      "Train Epoch: 67 [0/66 (0%)]\tLoss: 1.653484 Epoch_Loss: 1.653484\n",
      "Train Epoch: 68 [0/66 (0%)]\tLoss: 1.525034 Epoch_Loss: 1.525034\n",
      "Train Epoch: 69 [0/66 (0%)]\tLoss: 1.694963 Epoch_Loss: 1.694963\n",
      "Train Epoch: 70 [0/66 (0%)]\tLoss: 1.667306 Epoch_Loss: 1.667306\n",
      "Train Epoch: 71 [0/66 (0%)]\tLoss: 1.355164 Epoch_Loss: 1.355164\n",
      "Train Epoch: 72 [0/66 (0%)]\tLoss: 1.393623 Epoch_Loss: 1.393623\n",
      "Train Epoch: 73 [0/66 (0%)]\tLoss: 1.379904 Epoch_Loss: 1.379904\n",
      "Train Epoch: 74 [0/66 (0%)]\tLoss: 1.417550 Epoch_Loss: 1.417550\n",
      "Train Epoch: 75 [0/66 (0%)]\tLoss: 1.361795 Epoch_Loss: 1.361795\n",
      "Train Epoch: 76 [0/66 (0%)]\tLoss: 1.339825 Epoch_Loss: 1.339825\n",
      "Train Epoch: 77 [0/66 (0%)]\tLoss: 1.278543 Epoch_Loss: 1.278543\n",
      "Train Epoch: 78 [0/66 (0%)]\tLoss: 1.209245 Epoch_Loss: 1.209245\n",
      "Train Epoch: 79 [0/66 (0%)]\tLoss: 1.310684 Epoch_Loss: 1.310684\n",
      "Train Epoch: 80 [0/66 (0%)]\tLoss: 1.109031 Epoch_Loss: 1.109031\n",
      "Train Epoch: 81 [0/66 (0%)]\tLoss: 1.234305 Epoch_Loss: 1.234305\n",
      "Train Epoch: 82 [0/66 (0%)]\tLoss: 1.024534 Epoch_Loss: 1.024534\n",
      "Train Epoch: 83 [0/66 (0%)]\tLoss: 0.950805 Epoch_Loss: 0.950805\n",
      "Train Epoch: 84 [0/66 (0%)]\tLoss: 1.289569 Epoch_Loss: 1.289569\n",
      "Train Epoch: 85 [0/66 (0%)]\tLoss: 1.089105 Epoch_Loss: 1.089105\n",
      "Train Epoch: 86 [0/66 (0%)]\tLoss: 1.000781 Epoch_Loss: 1.000781\n",
      "Train Epoch: 87 [0/66 (0%)]\tLoss: 1.017166 Epoch_Loss: 1.017166\n",
      "Train Epoch: 88 [0/66 (0%)]\tLoss: 0.897454 Epoch_Loss: 0.897454\n",
      "Train Epoch: 89 [0/66 (0%)]\tLoss: 1.211779 Epoch_Loss: 1.211779\n",
      "Train Epoch: 90 [0/66 (0%)]\tLoss: 0.944961 Epoch_Loss: 0.944961\n",
      "Train Epoch: 91 [0/66 (0%)]\tLoss: 1.016988 Epoch_Loss: 1.016988\n",
      "Train Epoch: 92 [0/66 (0%)]\tLoss: 0.969297 Epoch_Loss: 0.969297\n",
      "Train Epoch: 93 [0/66 (0%)]\tLoss: 0.957722 Epoch_Loss: 0.957722\n",
      "Train Epoch: 94 [0/66 (0%)]\tLoss: 0.975322 Epoch_Loss: 0.975322\n",
      "Train Epoch: 95 [0/66 (0%)]\tLoss: 0.847342 Epoch_Loss: 0.847342\n",
      "Train Epoch: 96 [0/66 (0%)]\tLoss: 0.895971 Epoch_Loss: 0.895971\n",
      "Train Epoch: 97 [0/66 (0%)]\tLoss: 1.033389 Epoch_Loss: 1.033389\n",
      "Train Epoch: 98 [0/66 (0%)]\tLoss: 0.542057 Epoch_Loss: 0.542057\n",
      "Train Epoch: 99 [0/66 (0%)]\tLoss: 0.495537 Epoch_Loss: 0.495537\n",
      "Train Epoch: 100 [0/66 (0%)]\tLoss: 0.785417 Epoch_Loss: 0.785417\n",
      "Train Epoch: 101 [0/66 (0%)]\tLoss: 0.666101 Epoch_Loss: 0.666101\n",
      "Train Epoch: 102 [0/66 (0%)]\tLoss: 0.642232 Epoch_Loss: 0.642232\n",
      "Train Epoch: 103 [0/66 (0%)]\tLoss: 0.602125 Epoch_Loss: 0.602125\n",
      "Train Epoch: 104 [0/66 (0%)]\tLoss: 0.621894 Epoch_Loss: 0.621894\n",
      "Train Epoch: 105 [0/66 (0%)]\tLoss: 0.389441 Epoch_Loss: 0.389441\n",
      "Train Epoch: 106 [0/66 (0%)]\tLoss: 0.513697 Epoch_Loss: 0.513697\n",
      "Train Epoch: 107 [0/66 (0%)]\tLoss: 0.518895 Epoch_Loss: 0.518895\n",
      "Train Epoch: 108 [0/66 (0%)]\tLoss: 0.628131 Epoch_Loss: 0.628131\n",
      "Train Epoch: 109 [0/66 (0%)]\tLoss: 0.667526 Epoch_Loss: 0.667526\n",
      "Train Epoch: 110 [0/66 (0%)]\tLoss: 0.465793 Epoch_Loss: 0.465793\n",
      "Train Epoch: 111 [0/66 (0%)]\tLoss: 0.435366 Epoch_Loss: 0.435366\n",
      "Train Epoch: 112 [0/66 (0%)]\tLoss: 0.461269 Epoch_Loss: 0.461269\n",
      "Train Epoch: 113 [0/66 (0%)]\tLoss: 0.423765 Epoch_Loss: 0.423765\n",
      "Train Epoch: 114 [0/66 (0%)]\tLoss: 0.636634 Epoch_Loss: 0.636634\n",
      "Train Epoch: 115 [0/66 (0%)]\tLoss: 0.418299 Epoch_Loss: 0.418299\n",
      "Train Epoch: 116 [0/66 (0%)]\tLoss: 0.463061 Epoch_Loss: 0.463061\n",
      "Train Epoch: 117 [0/66 (0%)]\tLoss: 0.351562 Epoch_Loss: 0.351562\n",
      "Train Epoch: 118 [0/66 (0%)]\tLoss: 0.399314 Epoch_Loss: 0.399314\n",
      "Train Epoch: 119 [0/66 (0%)]\tLoss: 0.362341 Epoch_Loss: 0.362341\n",
      "Train Epoch: 120 [0/66 (0%)]\tLoss: 0.606152 Epoch_Loss: 0.606152\n",
      "Train Epoch: 121 [0/66 (0%)]\tLoss: 0.319938 Epoch_Loss: 0.319938\n",
      "Train Epoch: 122 [0/66 (0%)]\tLoss: 0.336781 Epoch_Loss: 0.336781\n",
      "Train Epoch: 123 [0/66 (0%)]\tLoss: 0.449641 Epoch_Loss: 0.449641\n",
      "Train Epoch: 124 [0/66 (0%)]\tLoss: 0.673579 Epoch_Loss: 0.673579\n",
      "Train Epoch: 125 [0/66 (0%)]\tLoss: 0.438661 Epoch_Loss: 0.438661\n",
      "Train Epoch: 126 [0/66 (0%)]\tLoss: 0.264034 Epoch_Loss: 0.264034\n",
      "Train Epoch: 127 [0/66 (0%)]\tLoss: 0.484780 Epoch_Loss: 0.484780\n",
      "Train Epoch: 128 [0/66 (0%)]\tLoss: 0.277035 Epoch_Loss: 0.277035\n",
      "Train Epoch: 129 [0/66 (0%)]\tLoss: 0.365177 Epoch_Loss: 0.365177\n",
      "Train Epoch: 130 [0/66 (0%)]\tLoss: 0.457893 Epoch_Loss: 0.457893\n",
      "Train Epoch: 131 [0/66 (0%)]\tLoss: 0.293309 Epoch_Loss: 0.293309\n",
      "Train Epoch: 132 [0/66 (0%)]\tLoss: 0.281207 Epoch_Loss: 0.281207\n",
      "Train Epoch: 133 [0/66 (0%)]\tLoss: 0.278437 Epoch_Loss: 0.278437\n",
      "Train Epoch: 134 [0/66 (0%)]\tLoss: 0.383608 Epoch_Loss: 0.383608\n",
      "Train Epoch: 135 [0/66 (0%)]\tLoss: 0.453027 Epoch_Loss: 0.453027\n",
      "Train Epoch: 136 [0/66 (0%)]\tLoss: 0.302635 Epoch_Loss: 0.302635\n",
      "Train Epoch: 137 [0/66 (0%)]\tLoss: 0.185288 Epoch_Loss: 0.185288\n",
      "Train Epoch: 138 [0/66 (0%)]\tLoss: 0.416425 Epoch_Loss: 0.416425\n",
      "Train Epoch: 139 [0/66 (0%)]\tLoss: 0.201688 Epoch_Loss: 0.201688\n",
      "Train Epoch: 140 [0/66 (0%)]\tLoss: 0.142984 Epoch_Loss: 0.142984\n",
      "Train Epoch: 141 [0/66 (0%)]\tLoss: 0.178760 Epoch_Loss: 0.178760\n",
      "Train Epoch: 142 [0/66 (0%)]\tLoss: 0.156686 Epoch_Loss: 0.156686\n",
      "Train Epoch: 143 [0/66 (0%)]\tLoss: 0.249937 Epoch_Loss: 0.249937\n",
      "Train Epoch: 144 [0/66 (0%)]\tLoss: 0.224622 Epoch_Loss: 0.224622\n",
      "Train Epoch: 145 [0/66 (0%)]\tLoss: 0.131185 Epoch_Loss: 0.131185\n",
      "Train Epoch: 146 [0/66 (0%)]\tLoss: 0.357860 Epoch_Loss: 0.357860\n",
      "Train Epoch: 147 [0/66 (0%)]\tLoss: 0.207530 Epoch_Loss: 0.207530\n",
      "Train Epoch: 148 [0/66 (0%)]\tLoss: 0.307861 Epoch_Loss: 0.307861\n",
      "Train Epoch: 149 [0/66 (0%)]\tLoss: 0.172803 Epoch_Loss: 0.172803\n",
      "Train Epoch: 150 [0/66 (0%)]\tLoss: 0.204437 Epoch_Loss: 0.204437\n",
      "Train Epoch: 151 [0/66 (0%)]\tLoss: 0.306633 Epoch_Loss: 0.306633\n",
      "Train Epoch: 152 [0/66 (0%)]\tLoss: 0.161425 Epoch_Loss: 0.161425\n",
      "Train Epoch: 153 [0/66 (0%)]\tLoss: 0.357851 Epoch_Loss: 0.357851\n",
      "Train Epoch: 154 [0/66 (0%)]\tLoss: 0.183386 Epoch_Loss: 0.183386\n",
      "Train Epoch: 155 [0/66 (0%)]\tLoss: 0.242846 Epoch_Loss: 0.242846\n",
      "Train Epoch: 156 [0/66 (0%)]\tLoss: 0.118712 Epoch_Loss: 0.118712\n",
      "Train Epoch: 157 [0/66 (0%)]\tLoss: 0.134032 Epoch_Loss: 0.134032\n",
      "Train Epoch: 158 [0/66 (0%)]\tLoss: 0.138326 Epoch_Loss: 0.138326\n",
      "Train Epoch: 159 [0/66 (0%)]\tLoss: 0.206356 Epoch_Loss: 0.206356\n",
      "Train Epoch: 160 [0/66 (0%)]\tLoss: 0.138273 Epoch_Loss: 0.138273\n",
      "Train Epoch: 161 [0/66 (0%)]\tLoss: 0.128434 Epoch_Loss: 0.128434\n",
      "Train Epoch: 162 [0/66 (0%)]\tLoss: 0.103930 Epoch_Loss: 0.103930\n",
      "Train Epoch: 163 [0/66 (0%)]\tLoss: 0.146768 Epoch_Loss: 0.146768\n",
      "Train Epoch: 164 [0/66 (0%)]\tLoss: 0.109745 Epoch_Loss: 0.109745\n",
      "Train Epoch: 165 [0/66 (0%)]\tLoss: 0.126799 Epoch_Loss: 0.126799\n",
      "Train Epoch: 166 [0/66 (0%)]\tLoss: 0.213435 Epoch_Loss: 0.213435\n",
      "Train Epoch: 167 [0/66 (0%)]\tLoss: 0.236623 Epoch_Loss: 0.236623\n",
      "Train Epoch: 168 [0/66 (0%)]\tLoss: 0.105304 Epoch_Loss: 0.105304\n",
      "Train Epoch: 169 [0/66 (0%)]\tLoss: 0.095453 Epoch_Loss: 0.095453\n",
      "Train Epoch: 170 [0/66 (0%)]\tLoss: 0.110140 Epoch_Loss: 0.110140\n",
      "Train Epoch: 171 [0/66 (0%)]\tLoss: 0.095511 Epoch_Loss: 0.095511\n",
      "Train Epoch: 172 [0/66 (0%)]\tLoss: 0.133676 Epoch_Loss: 0.133676\n",
      "Train Epoch: 173 [0/66 (0%)]\tLoss: 0.106454 Epoch_Loss: 0.106454\n",
      "Train Epoch: 174 [0/66 (0%)]\tLoss: 0.113984 Epoch_Loss: 0.113984\n",
      "Train Epoch: 175 [0/66 (0%)]\tLoss: 0.160607 Epoch_Loss: 0.160607\n",
      "Train Epoch: 176 [0/66 (0%)]\tLoss: 0.113755 Epoch_Loss: 0.113755\n",
      "Train Epoch: 177 [0/66 (0%)]\tLoss: 0.084806 Epoch_Loss: 0.084806\n",
      "Train Epoch: 178 [0/66 (0%)]\tLoss: 0.101079 Epoch_Loss: 0.101079\n",
      "Train Epoch: 179 [0/66 (0%)]\tLoss: 0.086741 Epoch_Loss: 0.086741\n",
      "Train Epoch: 180 [0/66 (0%)]\tLoss: 0.197954 Epoch_Loss: 0.197954\n",
      "Train Epoch: 181 [0/66 (0%)]\tLoss: 0.104011 Epoch_Loss: 0.104011\n",
      "Train Epoch: 182 [0/66 (0%)]\tLoss: 0.088168 Epoch_Loss: 0.088168\n",
      "Train Epoch: 183 [0/66 (0%)]\tLoss: 0.091619 Epoch_Loss: 0.091619\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[122], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m lossv \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epoch_start, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 22\u001B[0m     lossv\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[118], line 9\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epoch, log_interval)\u001B[0m\n\u001B[1;32m      6\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      7\u001B[0m target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 9\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Pass data through the network\u001B[39;00m\n\u001B[1;32m     12\u001B[0m output \u001B[38;5;241m=\u001B[39m model(data)\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/torch/_compile.py:32\u001B[0m, in \u001B[0;36m_disable_dynamo.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     29\u001B[0m     disable_fn \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mdisable(fn, recursive)\n\u001B[1;32m     30\u001B[0m     fn\u001B[38;5;241m.\u001B[39m__dynamo_disable \u001B[38;5;241m=\u001B[39m disable_fn\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdisable_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/torch/_dynamo/eval_frame.py:632\u001B[0m, in \u001B[0;36mDisableContext.__call__.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    630\u001B[0m prior \u001B[38;5;241m=\u001B[39m _maybe_set_eval_frame(callback)\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    634\u001B[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/torch/optim/optimizer.py:952\u001B[0m, in \u001B[0;36mOptimizer.zero_grad\u001B[0;34m(self, set_to_none)\u001B[0m\n\u001B[1;32m    950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    951\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m set_to_none:\n\u001B[0;32m--> 952\u001B[0m         \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    953\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    954\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgrad\u001B[38;5;241m.\u001B[39mgrad_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:32.694527Z",
     "start_time": "2024-12-03T13:06:56.883790Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), './models/model_1000_epochs.pth')",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:32.694935Z",
     "start_time": "2024-12-03T13:24:08.171292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def GetItem(y):\n",
    "\n",
    "    img_name = \"\"\n",
    "    for i in range(len(files)):\n",
    "        if files[i][1] == y:\n",
    "            idx = i\n",
    "            break\n",
    "\n",
    "    img_name = files[idx][0]\n",
    "    img = cv2.imread(img_name, cv2.COLOR_RGB2GRAY)\n",
    "    image = img\n",
    "    image = cv2.resize(image,(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = cv2.bitwise_not(image) / 255\n",
    "    image = np.asarray(image).astype(float)#.reshape(3,self.img_size,self.img_size)\n",
    "\n",
    "    target = [0 for i in range(NUM_CLASSES)]\n",
    "    target[files[idx][1]] = 1\n",
    "    target = torch.FloatTensor(target)\n",
    "\n",
    "    image = torch.FloatTensor(image[:,:,0])\n",
    "\n",
    "    return image,target,files[idx][1]\n"
   ],
   "id": "5de4309bd8ebd5d5",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T13:34:32.695274Z",
     "start_time": "2024-12-03T13:24:58.179494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_model = Net().to(device)\n",
    "my_model.load_state_dict(torch.load('./models/model_1000_epochs.pth'))\n",
    "my_model.eval()\n",
    "\n",
    "value = \"1 0 + 3 - 6\" # Строка для создания массива картинок\n",
    "end = \"\"\n",
    "for i in value.split(\" \"):\n",
    "    (X_train, y_train,class_idx) = GetItem(dict_folders[i]) # Получаем текущую картинку\n",
    "    result = my_model(X_train) # Предсказываем поведение\n",
    "    temp = list(dict_folders.keys())[list(dict_folders.values()).index(int(torch.argmax(result)))] # Вычлисляем действительное значение данной модели\n",
    "    end += temp # Сохраняем\n",
    "    print(temp, end=\"\") # Выводим\n",
    "\n",
    "print(f\"={eval(end)}\") # Расчет значения (не будет работать для * и букв)"
   ],
   "id": "4f9b359cc6b3854c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/889mcdgx68s4l2p7x5f310hm0000gn/T/ipykernel_74642/3854142012.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  my_model.load_state_dict(torch.load('./models/model_1000_epochs.pth'))\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'idx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[114], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m end \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m value\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m----> 8\u001B[0m     (X_train, y_train,class_idx) \u001B[38;5;241m=\u001B[39m \u001B[43mGetItem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdict_folders\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Получаем текущую картинку\u001B[39;00m\n\u001B[1;32m      9\u001B[0m     result \u001B[38;5;241m=\u001B[39m my_model(X_train) \u001B[38;5;66;03m# Предсказываем поведение\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     temp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(dict_folders\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;28mlist\u001B[39m(dict_folders\u001B[38;5;241m.\u001B[39mvalues())\u001B[38;5;241m.\u001B[39mindex(\u001B[38;5;28mint\u001B[39m(torch\u001B[38;5;241m.\u001B[39margmax(result)))] \u001B[38;5;66;03m# Вычлисляем действительное значение данной модели\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[112], line 9\u001B[0m, in \u001B[0;36mGetItem\u001B[0;34m(y)\u001B[0m\n\u001B[1;32m      6\u001B[0m         idx \u001B[38;5;241m=\u001B[39m i\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m img_name \u001B[38;5;241m=\u001B[39m files[\u001B[43midx\u001B[49m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     10\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(img_name, cv2\u001B[38;5;241m.\u001B[39mCOLOR_RGB2GRAY)\n\u001B[1;32m     11\u001B[0m image \u001B[38;5;241m=\u001B[39m img\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: local variable 'idx' referenced before assignment"
     ]
    }
   ],
   "execution_count": 114
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
